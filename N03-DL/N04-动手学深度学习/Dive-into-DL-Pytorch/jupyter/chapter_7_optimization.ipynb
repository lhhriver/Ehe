{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.1 优化与深度学习\n",
    "## 7.1.2 优化在深度学习中的挑战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "from mpl_toolkits import mplot3d # 三维画图\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.2.1 局部最小值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x * np.cos(np.pi * x)\n",
    "\n",
    "d2l.set_figsize((8, 6))\n",
    "x = np.arange(-1.0, 2.0, 0.1)\n",
    "fig,  = d2l.plt.plot(x, f(x))\n",
    "fig.axes.annotate('local minimum', xy=(-0.3, -0.25), xytext=(-0.77, -1.0),\n",
    "                  arrowprops=dict(arrowstyle='->'))\n",
    "fig.axes.annotate('global minimum', xy=(1.1, -0.95), xytext=(0.6, 0.8),\n",
    "                  arrowprops=dict(arrowstyle='->'))\n",
    "d2l.plt.xlabel('x')\n",
    "d2l.plt.ylabel('f(x)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.2.2 鞍点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-2.0, 2.0, 0.1)\n",
    "fig, = d2l.plt.plot(x, x**3)\n",
    "fig.axes.annotate('saddle point', xy=(0, -0.2), xytext=(-0.52, -5.0),\n",
    "                  arrowprops=dict(arrowstyle='->'))\n",
    "d2l.plt.xlabel('x')\n",
    "d2l.plt.ylabel('f(x)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "x, y = np.mgrid[-1: 1: 31j, -1: 1: 31j]\n",
    "z = x**2 - y**2\n",
    "\n",
    "ax = d2l.plt.figure().add_subplot(111, projection='3d')\n",
    "ax.plot_wireframe(x, y, z, **{'rstride': 2, 'cstride': 2})\n",
    "ax.plot([0], [0], [0], 'rx')\n",
    "ticks = [-1,  0, 1]\n",
    "d2l.plt.xticks(ticks)\n",
    "d2l.plt.yticks(ticks)\n",
    "ax.set_zticks(ticks)\n",
    "d2l.plt.xlabel('x')\n",
    "d2l.plt.ylabel('y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2 梯度下降和随机梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2.1 一维梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(eta):\n",
    "    x = 10\n",
    "    results = [x]\n",
    "    for i in range(10):\n",
    "        x -= eta * 2 * x  # f(x) = x * x的导数为f'(x) = 2 * x\n",
    "        results.append(x)\n",
    "    print('epoch 10, x:', x)\n",
    "    return results\n",
    "\n",
    "res = gd(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_trace(res):\n",
    "    n = max(abs(min(res)), abs(max(res)), 10)\n",
    "    f_line = np.arange(-n, n, 0.1)\n",
    "    d2l.set_figsize()\n",
    "    d2l.plt.plot(f_line, [x * x for x in f_line])\n",
    "    d2l.plt.plot(res, [x * x for x in res], '-o')\n",
    "    d2l.plt.xlabel('x')\n",
    "    d2l.plt.ylabel('f(x)')\n",
    "\n",
    "show_trace(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2.2 学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_trace(gd(0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_trace(gd(1.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2.3 多维梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_2d(trainer):  # 本函数将保存在d2lzh_pytorch包中方便以后使用\n",
    "    x1, x2, s1, s2 = -5, -2, 0, 0  # s1和s2是自变量状态，本章后续几节会使用\n",
    "    results = [(x1, x2)]\n",
    "    for i in range(20):\n",
    "        x1, x2, s1, s2 = trainer(x1, x2, s1, s2)\n",
    "        results.append((x1, x2))\n",
    "    print('epoch %d, x1 %f, x2 %f' % (i + 1, x1, x2))\n",
    "    return results\n",
    "\n",
    "def show_trace_2d(f, results):  # 本函数将保存在d2lzh_pytorch包中方便以后使用\n",
    "    d2l.plt.plot(*zip(*results), '-o', color='#ff7f0e')\n",
    "    x1, x2 = np.meshgrid(np.arange(-5.5, 1.0, 0.1), np.arange(-3.0, 1.0, 0.1))\n",
    "    d2l.plt.contour(x1, x2, f(x1, x2), colors='#1f77b4')\n",
    "    d2l.plt.xlabel('x1')\n",
    "    d2l.plt.ylabel('x2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.1\n",
    "\n",
    "def f_2d(x1, x2):  # 目标函数\n",
    "    return x1 ** 2 + 2 * x2 ** 2\n",
    "\n",
    "def gd_2d(x1, x2, s1, s2):\n",
    "    return (x1 - eta * 2 * x1, x2 - eta * 4 * x2, 0, 0)\n",
    "\n",
    "show_trace_2d(f_2d, train_2d(gd_2d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2.4 随机梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def sgd_2d(x1, x2, s1, s2):\n",
    "    return (x1 - eta * (2 * x1 + np.random.normal(0.1)),\n",
    "            x2 - eta * (4 * x2 + np.random.normal(0.1)), 0, 0)\n",
    "\n",
    "show_trace_2d(f_2d, train_2d(sgd_2d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.3 小批量随机梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3.1 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_ch7():  # 本函数已保存在d2lzh_pytorch包中方便以后使用\n",
    "    data = np.genfromtxt('../../data/airfoil_self_noise.dat', delimiter='\\t')\n",
    "    data = (data - data.mean(axis=0)) / data.std(axis=0) # 标准化\n",
    "    return torch.tensor(data[:1500, :-1], dtype=torch.float32), \\\n",
    "           torch.tensor(data[:1500, -1], dtype=torch.float32) # 前1500个样本(每个样本5个特征)\n",
    "\n",
    "features, labels = get_data_ch7()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3.2 从零开始实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, states, hyperparams):\n",
    "    for p in params:\n",
    "        p.data -= hyperparams['lr'] * p.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本函数已保存在d2lzh_pytorch包中方便以后使用\n",
    "def train_ch7(optimizer_fn, states, hyperparams, features, labels,\n",
    "              batch_size=10, num_epochs=2):\n",
    "    # 初始化模型\n",
    "    net, loss = d2l.linreg, d2l.squared_loss\n",
    "    \n",
    "    w = torch.nn.Parameter(torch.tensor(np.random.normal(0, 0.01, size=(features.shape[1], 1)), dtype=torch.float32),\n",
    "                           requires_grad=True)\n",
    "    b = torch.nn.Parameter(torch.zeros(1, dtype=torch.float32), requires_grad=True)\n",
    "\n",
    "    def eval_loss():\n",
    "        return loss(net(features, w, b), labels).mean().item()\n",
    "\n",
    "    ls = [eval_loss()]\n",
    "    data_iter = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(features, labels), batch_size, shuffle=True)\n",
    "    \n",
    "    for _ in range(num_epochs):\n",
    "        start = time.time()\n",
    "        for batch_i, (X, y) in enumerate(data_iter):\n",
    "            l = loss(net(X, w, b), y).mean()  # 使用平均损失\n",
    "            \n",
    "            # 梯度清零\n",
    "            if w.grad is not None:\n",
    "                w.grad.data.zero_()\n",
    "                b.grad.data.zero_()\n",
    "                \n",
    "            l.backward()\n",
    "            optimizer_fn([w, b], states, hyperparams)  # 迭代模型参数\n",
    "            if (batch_i + 1) * batch_size % 100 == 0:\n",
    "                ls.append(eval_loss())  # 每100个样本记录下当前训练误差\n",
    "    # 打印结果和作图\n",
    "    print('loss: %f, %f sec per epoch' % (ls[-1], time.time() - start))\n",
    "    d2l.set_figsize()\n",
    "    d2l.plt.plot(np.linspace(0, num_epochs, len(ls)), ls)\n",
    "    d2l.plt.xlabel('epoch')\n",
    "    d2l.plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sgd(lr, batch_size, num_epochs=2):\n",
    "    train_ch7(sgd, None, {'lr': lr}, features, labels, batch_size, num_epochs)\n",
    "\n",
    "train_sgd(1, 1500, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sgd(0.005, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sgd(0.05, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3.3 简洁实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本函数与原书不同的是这里第一个参数优化器函数而不是优化器的名字\n",
    "# 例如: optimizer_fn=torch.optim.SGD, optimizer_hyperparams={\"lr\": 0.05}\n",
    "def train_pytorch_ch7(optimizer_fn, optimizer_hyperparams, features, labels,\n",
    "                    batch_size=10, num_epochs=2):\n",
    "    # 初始化模型\n",
    "    net = nn.Sequential(\n",
    "        nn.Linear(features.shape[-1], 1)\n",
    "    )\n",
    "    loss = nn.MSELoss()\n",
    "    optimizer = optimizer_fn(net.parameters(), **optimizer_hyperparams)\n",
    "\n",
    "    def eval_loss():\n",
    "        return loss(net(features).view(-1), labels).item() / 2\n",
    "\n",
    "    ls = [eval_loss()]\n",
    "    data_iter = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(features, labels), batch_size, shuffle=True)\n",
    "\n",
    "    for _ in range(num_epochs):\n",
    "        start = time.time()\n",
    "        for batch_i, (X, y) in enumerate(data_iter):\n",
    "            # 除以2是为了和train_ch7保持一致, 因为squared_loss中除了2\n",
    "            l = loss(net(X).view(-1), y) / 2 \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            if (batch_i + 1) * batch_size % 100 == 0:\n",
    "                ls.append(eval_loss())\n",
    "    # 打印结果和作图\n",
    "    print('loss: %f, %f sec per epoch' % (ls[-1], time.time() - start))\n",
    "    d2l.set_figsize()\n",
    "    d2l.plt.plot(np.linspace(0, num_epochs, len(ls)), ls)\n",
    "    d2l.plt.xlabel('epoch')\n",
    "    d2l.plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "train_pytorch_ch7(optim.SGD, {\"lr\": 0.05}, features, labels, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.4 动量法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "import torch\n",
    "\n",
    "eta = 0.4\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4.1 梯度下降的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_2d(x1, x2):\n",
    "    return 0.1 * x1 ** 2 + 2 * x2 ** 2\n",
    "\n",
    "def gd_2d(x1, x2, s1, s2):\n",
    "    return (x1 - eta * 0.2 * x1, x2 - eta * 4 * x2, 0, 0)\n",
    "\n",
    "d2l.show_trace_2d(f_2d, d2l.train_2d(gd_2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.6\n",
    "d2l.show_trace_2d(f_2d, d2l.train_2d(gd_2d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4.2 动量法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum_2d(x1, x2, v1, v2):\n",
    "    v1 = gamma * v1 + eta * 0.2 * x1\n",
    "    v2 = gamma * v2 + eta * 4 * x2\n",
    "    return x1 - v1, x2 - v2, v1, v2\n",
    "\n",
    "eta, gamma = 0.4, 0.5\n",
    "d2l.show_trace_2d(f_2d, d2l.train_2d(momentum_2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.6\n",
    "d2l.show_trace_2d(f_2d, d2l.train_2d(momentum_2d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4.3 从零开始实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = d2l.get_data_ch7()\n",
    "\n",
    "def init_momentum_states():\n",
    "    v_w = torch.zeros((features.shape[1], 1), dtype=torch.float32)\n",
    "    v_b = torch.zeros(1, dtype=torch.float32)\n",
    "    return (v_w, v_b)\n",
    "\n",
    "def sgd_momentum(params, states, hyperparams):\n",
    "    for p, v in zip(params, states):\n",
    "        v.data = hyperparams['momentum'] * v.data + hyperparams['lr'] * p.grad.data\n",
    "        p.data -= v.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.train_ch7(sgd_momentum, init_momentum_states(),\n",
    "              {'lr': 0.02, 'momentum': 0.5}, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.train_ch7(sgd_momentum, init_momentum_states(),\n",
    "              {'lr': 0.02, 'momentum': 0.9}, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.train_ch7(sgd_momentum, init_momentum_states(),\n",
    "              {'lr': 0.004, 'momentum': 0.9}, features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4.4 简洁实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.train_pytorch_ch7(torch.optim.SGD, {'lr': 0.004, 'momentum': 0.9},\n",
    "                    features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.5 AdaGrad算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5.2 特点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adagrad_2d(x1, x2, s1, s2):\n",
    "    g1, g2, eps = 0.2 * x1, 4 * x2, 1e-6  # 前两项为自变量梯度\n",
    "    s1 += g1 ** 2\n",
    "    s2 += g2 ** 2\n",
    "    x1 -= eta / math.sqrt(s1 + eps) * g1\n",
    "    x2 -= eta / math.sqrt(s2 + eps) * g2\n",
    "    return x1, x2, s1, s2\n",
    "\n",
    "def f_2d(x1, x2):\n",
    "    return 0.1 * x1 ** 2 + 2 * x2 ** 2\n",
    "\n",
    "eta = 0.4\n",
    "d2l.show_trace_2d(f_2d, d2l.train_2d(adagrad_2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 2\n",
    "d2l.show_trace_2d(f_2d, d2l.train_2d(adagrad_2d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5.3 从零开始实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = d2l.get_data_ch7()\n",
    "\n",
    "def init_adagrad_states():\n",
    "    s_w = torch.zeros((features.shape[1], 1), dtype=torch.float32)\n",
    "    s_b = torch.zeros(1, dtype=torch.float32)\n",
    "    return (s_w, s_b)\n",
    "\n",
    "def adagrad(params, states, hyperparams):\n",
    "    eps = 1e-6\n",
    "    for p, s in zip(params, states):\n",
    "        s.data += (p.grad.data**2)\n",
    "        p.data -= hyperparams['lr'] * p.grad.data / torch.sqrt(s + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.train_ch7(adagrad, init_adagrad_states(), {'lr': 0.1}, features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5.4 简洁实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "d2l.train_pytorch_ch7(torch.optim.Adagrad, {'lr': 0.1}, features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.6 RMSProp算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6.1 算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsprop_2d(x1, x2, s1, s2):\n",
    "    g1, g2, eps = 0.2 * x1, 4 * x2, 1e-6\n",
    "    s1 = gamma * s1 + (1 - gamma) * g1 ** 2\n",
    "    s2 = gamma * s2 + (1 - gamma) * g2 ** 2\n",
    "    x1 -= eta / math.sqrt(s1 + eps) * g1\n",
    "    x2 -= eta / math.sqrt(s2 + eps) * g2\n",
    "    return x1, x2, s1, s2\n",
    "\n",
    "def f_2d(x1, x2):\n",
    "    return 0.1 * x1 ** 2 + 2 * x2 ** 2\n",
    "\n",
    "eta, gamma = 0.4, 0.9\n",
    "d2l.show_trace_2d(f_2d, d2l.train_2d(rmsprop_2d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6.2 从零开始实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = d2l.get_data_ch7()\n",
    "\n",
    "def init_rmsprop_states():\n",
    "    s_w = torch.zeros((features.shape[1], 1), dtype=torch.float32)\n",
    "    s_b = torch.zeros(1, dtype=torch.float32)\n",
    "    return (s_w, s_b)\n",
    "\n",
    "def rmsprop(params, states, hyperparams):\n",
    "    gamma, eps = hyperparams['gamma'], 1e-6\n",
    "    for p, s in zip(params, states):\n",
    "        s.data = gamma * s.data + (1 - gamma) * (p.grad.data)**2\n",
    "        p.data -= hyperparams['lr'] * p.grad.data / torch.sqrt(s + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.train_ch7(rmsprop, init_rmsprop_states(), {'lr': 0.01, 'gamma': 0.9},\n",
    "              features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6.3 简洁实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "d2l.train_pytorch_ch7(torch.optim.RMSprop, {'lr': 0.01, 'alpha': 0.9},\n",
    "                    features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.7 AdaDelta算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "\n",
    "features, labels = d2l.get_data_ch7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.7.1 算法\n",
    "## 7.7.2 从零开始实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_adadelta_states():\n",
    "    s_w, s_b = torch.zeros((features.shape[1], 1), dtype=torch.float32), torch.zeros(1, dtype=torch.float32)\n",
    "    delta_w, delta_b = torch.zeros((features.shape[1], 1), dtype=torch.float32), torch.zeros(1, dtype=torch.float32)\n",
    "    return ((s_w, delta_w), (s_b, delta_b))\n",
    "\n",
    "def adadelta(params, states, hyperparams):\n",
    "    rho, eps = hyperparams['rho'], 1e-5\n",
    "    for p, (s, delta) in zip(params, states):\n",
    "        s[:] = rho * s + (1 - rho) * (p.grad.data**2)\n",
    "        g =  p.grad.data * torch.sqrt((delta + eps) / (s + eps))\n",
    "        p.data -= g\n",
    "        delta[:] = rho * delta + (1 - rho) * g * g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.train_ch7(adadelta, init_adadelta_states(), {'rho': 0.9}, features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.7.3 简洁实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "d2l.train_pytorch_ch7(torch.optim.Adadelta, {'rho': 0.9}, features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.8 Adam算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "\n",
    "features, labels = d2l.get_data_ch7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.8.2 从零开始实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_adam_states():\n",
    "    v_w, v_b = torch.zeros((features.shape[1], 1), dtype=torch.float32), torch.zeros(1, dtype=torch.float32)\n",
    "    s_w, s_b = torch.zeros((features.shape[1], 1), dtype=torch.float32), torch.zeros(1, dtype=torch.float32)\n",
    "    return ((v_w, s_w), (v_b, s_b))\n",
    "\n",
    "def adam(params, states, hyperparams):\n",
    "    beta1, beta2, eps = 0.9, 0.999, 1e-6\n",
    "    for p, (v, s) in zip(params, states):\n",
    "        v[:] = beta1 * v + (1 - beta1) * p.grad.data\n",
    "        s[:] = beta2 * s + (1 - beta2) * p.grad.data**2\n",
    "        v_bias_corr = v / (1 - beta1 ** hyperparams['t'])\n",
    "        s_bias_corr = s / (1 - beta2 ** hyperparams['t'])\n",
    "        p.data -= hyperparams['lr'] * v_bias_corr / (torch.sqrt(s_bias_corr) + eps)\n",
    "    hyperparams['t'] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.8.3 简洁实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.train_ch7(adam, init_adam_states(), {'lr': 0.01, 't': 1}, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "d2l.train_pytorch_ch7(torch.optim.Adam, {'lr': 0.01}, features, labels)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
