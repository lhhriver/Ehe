# 在线模型结构

## 总体架构

![](https://gitee.com/liuhuihe/Ehe/raw/master/images/ASR培训-20220302-134501-277071.png)



### 模型结构

#### transfomer

![](https://gitee.com/liuhuihe/Ehe/raw/master/images/ASR培训-20220302-134501-288391.png)

#### 流式端到端语音识别

![](https://gitee.com/liuhuihe/Ehe/raw/master/images/ASR培训-20220302-134501-300370.png)

在线语音识别不同于离线，在线语音识别不能获取一段录音的所有特征，因此需要对transformer模型结构进行改进，主要包括以下几点：

1. Chunk-SAE
2. State reuse chunk-SAE
3. MTA based SAD

#### Chunk-SAE

1. 首先将语音切分成无重叠的N_c大小的chunk
2. 为了获取上下文信息，进行拼接，左拼N_l长度，右拼N_r长度，延时大小为N_r
3. 相关参数
    - encoder_left_chunk: 96
    - encoder_center_chunk: 64
    - encoder_right_chunk: 32

![](https://gitee.com/liuhuihe/Ehe/raw/master/images/ASR培训-20220302-134501-315016.png)

#### State reuse chunk-SAE

s_τ^l∈R^N_l×d_m代表第τ个chunk第l层的存储的隐层状态_
h_τ^l∈R^(N_c+N_r)×d_m代表第τ个chunk第l层的新计算的隐层状态



![](https://gitee.com/liuhuihe/Ehe/raw/master/images/ASR培训-20220302-134501-328998.png)



#### MTA based SAD

- 其中r为可训练的参数，ε为高斯噪声，定义P={p_i,j)}为截断概率矩阵，其中p_i,j代表预测第i个输出label时，截断第j个SAE输出的概率。

- cumprod(x)=[1,x_1,x_1x_2,…,∏_k=1^|x|−1▒x_k]，该操作用在P的每一行上

- ⊙该操作代表对应元素位置乘

**

- 解码阶段，一行一行计算P^l={p_i,j^l}, P^l是第l层的截断注意力矩阵，t_i^l代表第l层预测第i个label输出时截断点
- z_i,j^l代表第l层是否截断第j个SAE的输出，‖代表指示函数，z_i,j^l等于1时，进行截断，j=t_i^l

### 损失函数

相较于离线的损失函数，在线损失函数增加了align时间点对齐损失，如下：
		L_MTL=λL_CTC +(1− λ) L_ATT+L_Ali，0< λ<1

# 模型训练流程

![](https://gitee.com/liuhuihe/Ehe/raw/master/images/ASR培训-20220302-134501-341656.png)

# 源代码

## 语音识别模型

语音识别模型对应代码模块为：

1. bin.taskegs/pytorch_backend.task_ctc_att_online.py	任务类
2. eteh.models.pytorch_backend.model.e2e: E2E_Transformer_CTC_Online	构建整体模型结构
3. eteh.models.pytorch_backend.net.transformer	transfomer模型组件
4. eteh.models.pytorch_backend.criterion	损失函数

## 训练任务构建

![](https://gitee.com/liuhuihe/Ehe/raw/master/images/ASR培训-20220302-134501-353627.png)



### 数据中心

- 数据中心主要负责对数据的筛选、排序、切分、打包等预处理工作，对数据进行统一管理
    1. eteh.data.data:Data
    2. eteh.data.data:Label
    3. eteh.data.datacenter: DataCenter				数据管理中心，数据处理的入口
    4. eteh.data.dataloader: StandDataLoader				继承torch.utils.data.DataSet类，实现数据加载
    5. eteh.data.dataset: BaseDataSet					继承torch.utils.data.DataSet类
    6. eteh.data.dataset: JsonDataPacker	对json数据进行封装



### 训练器

训练器使用Adam优化器

![](https://gitee.com/liuhuihe/Ehe/raw/master/images/ASR培训-20220302-134501-364944.png)

- eteh.tools.trainer:Trainer
- eteh.tools.interface.pytorch_backend.th_trainer: TH_Trainer



### 监控器

监控器主要实现tensorboard日志输出和其他日志输出，主要代码包括

1. eteh.tools.reporter:Reporter
2. eteh.tools.observer:ReporterObserver
3. eteh.tools.observer: TensorBoardObserver
4. bin.taskegs.pytorch_backend.task_ctc_att: E2E_Observer
5. bin.taskegs.pytorch_backend.task_ctc_att: E2E_Observer_tensorboard

E2E_Observer继承了ReporterObserver，主要输出其他类型日志，E2E_Observer_tensorboard继承了TensorBoardObserver，输出tensorboard日志。

输出日志项包括：{Time：耗时, Lr：学习率, Corr：字正确率, Att-Loss：attention损失, Ctc-Loss：ctc损失}



### 验证器

验证器主要实现对验证集进行性能验证

![](https://gitee.com/liuhuihe/Ehe/raw/master/images/ASR培训-20220302-134501-376925.png)

- eteh.tools.valider: Valider
- bin.taskegs.pytorch_backend.task_ctc_att: E2E_Valid

### 任务管理器

任务管理器实现对训练任务的管理，管理模型、训练、验证以及数据的获取和传送，是本平台的训练任务的核心模块。

1. bin.taskegs.pytorch_backend.task_ctc_att_online:CtcAttOnlineTask
2. eteh.tools.interface.pytorch_backend.th_task: TH_Task
3. eteh.tools.task: EtehTask 	核心类



# 模型训练、预测、评估

## 模型训练目录结构

1. eteh-v2-release-JXJK2021_orig_online_v2_release
    |--bin				模型训练入口函数
    |--eteh				模型训练核心代码模块
    |--example			示例
    	|--hkust_egs
    		|--baseModel			基线模型
    		|--conf				相关配置
    		|--output			存放输入输出数据
    		|--run_train.sh		训练脚本
    		|--run_predictor.sh 		预测脚本
    		|--run_evaluate.sh		评估脚本
    |--utils				工具类



## 模型训练

模型训练脚本位于example/hkust_egs/run_train.sh

参数说明：

1. exp_dir=output/exp		模型输出路径
2. ​	train_config=conf/ce_espnet_baseline_fintune.yaml 模型训练配置
3. ​	data_conf=conf/data.yaml	训练数据yaml文件
4. ​	checkpoint=baseModel/checkpoint.29		基线模型

运行方法：

1.  ./run_train.sh



## 预测

模型预测脚本位于example/hkust_egs/run_predictor.sh

参数说明：

1.  exp_dir=output/exp		模型输出路径

2. ​	train_config=conf/ce_espnet_baseline_fintune.yaml 模型训练配置

3. ​	data_conf=conf/data.yaml	训练数据yaml文件

4. ​	char_list=baseModel/vocab.kefu_cts.txt	字典文件

5. ​	checkpoint=baseModel/checkpoint.29	基线模型

    

运行方法：

1.  ./run_ predictor.sh



## 评估

模型评估脚本位于example/hkust_egs/run_evaluate.sh

参数说明：

1.  rec=your result file		结果文件
2. ​	ref=your ref file			答案文件



运行方法：

1.  ./run_evaluate.sh

    

执行完成后，会在结果所在路径生成.sys文件，为识别率测试结果，如下：

​	SPKR   |  # Snt # Chr   |  Corr  Sub  Del  Ins  Err  S.Err

​	Sum/Avg |   213  6108  |  86.5  10.5  3.0  2.6  16.0  69.0 

​	由上述结果可知，字正确率为86.5%，字错误率为16%。

# 模型配置

## 优化器配置

opti_config:

1.  name: 'eteh.models.pytorch_backend.optimizer.optimizer:Noam'	优化器类型
2. ​    factor: 1		学习率影响因子，调到，学习率会放大
3. ​    warm_step: 25000
4. ​    model_size: 256

## 损失函数配置

criterion_config:

1.  name: 'eteh.models.pytorch_backend.model.e2e: E2E_Transformer_CTC_Online' 定义要用的损失函数
2. ​    size: 5720					字典大小
3. ​    padding_idx: -1				padding值
4. ​    smoothing: 0.1				标签平滑参数
5. ​    rate: 0.3    					ctc损失函数占比
6. ​    ali_rate: 1.0			align损失函数占比
7. ​    ali_type: "mid"		align取每个字中间时间位置计算损失

## 模型配置


model_config:

1. name: 'eteh.models.pytorch_backend.model.e2e:E2E_Transformer_CTC'	模型
2. ​    idim: 40					输入数据特征维度
3. ​    odim: 5720					输出维度，字典大小
4. ​    encoder_attention_dim: 320			编码器注意力维度
5. ​    encoder_attention_heads: 8			编码器注意力头个数
6. ​    encoder_linear_units: 2048			编码器线性层维度
7. ​    encoder_num_blocks: 14			编码器block个数
8. ​    encoder_input_layer: conv2d		编码器的输入
9. ​    encoder_dropout_rate: 0.1			编码器的dropout概率
10. ​    encoder_attention_dropout_rate: 0	编码器attention的dropout概率
11. ​    encoder_left_chunk: 96				编码器历史信息chunk大小
12. ​    encoder_center_chunk: 64			编码器当前chunk大小
13. ​    encoder_right_chunk: 32			编码器未来信息chunk大小
14. ​    decoder_attention_dim: 320			解码器注意力维度
15. ​    decoder_attention_heads: 4			解码器注意力头个数
16. ​    decoder_src_attention_heads: 1	解码器src attention注意力头个数
17. ​    decoder_linear_units: 2048			解码器线性层维度
18. ​    decoder_input_layer: embed			解码器输入
19. ​    decoder_num_block: 7				解码器block个数
20. ​    decoder_dropout_rate: 0.1			解码器dropout概率
21. ​    decoder_src_attention_dropout_rate: 0
22. ​    decoder_self_attention_dropout_rate: 0
23. ​    ctc_dropout: 0.1				ctc dropout概率



## 训练参数配置


train_config:

1.  char_num: 5720				字典大小
2. ​    accum_grad: 2 #must be 1 when amp is used		梯度累积
3. ​    amp: False

## 训练数据配置

1. batch_size: 16			batch_size大小
2. ​        min_batch_size: 1			最小的batch_size大小
3. ​        shortest_first: True			按最短优先对数据进行排序
4. ​        batch_sort_key: "input"		按input数据长度对数据进行排序
5. ​        count: "seq"		采用seq方式进行batch打包
6. ​        clean_data: True			是否对数据进行清洗
7. ​        ilen_max: 2000			最大输入长度，单位为帧
8. ​        ilen_min: 17			最小输入长度，单位为帧
9. ​        olen_max: 100			最大输出长度